<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="AIMP Labs aims at making AI research more mainstream in and around Kolkata. As a research based organization, AIMP has a long term vision of conducting high-impact research, promoting future researchers, and creating technologies of the future.">
    <meta name="keywords" content="Artificial intelligence & machine perception, computer vision, deep learning, cloud and edge IOT, Kolkata">
    <meta name="author" content="AIMP LABS, Kolkata">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" />
    <link rel="stylesheet" href="../../css/aimp_navfoot.css">
    <link rel="stylesheet" href="../../css/aimp_blogs.css">
    <title>Hands on Git tutorial</title>
    <script src="https://kit.fontawesome.com/2b92be31d1.js" crossorigin="anonymous"></script>
    <script
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
    type="text/javascript"></script>
    <link rel="stylesheet" href="../../css/default.min.css">
    <script src="../../js/highlight.min.js"></script>
    <script>hljs.highlightAll();</script>
</head>
</head>
<body>

<header class="jv-brand-container-center">
    <nav class="jv-navbar-flex">
            <div class="jv-logo-container">
                <img class="jv-brand-logo" src="../../assets/brand_imgs/aimplogo_small.png" alt="AIMP Logo">
                <div class="jv-brand-statements">
                    <div class="jv-brand-name"><a href="../../index.html">AIMP LABS</a></div>
                    <div class="jv-brand-desc"><a href="../../index.html">Private AI Research & Training Center</a></div>
                </div>
            </div>
            <div class="menu-icon" onclick="setsidenav()">
                <span class="material-symbols-outlined">menu</span>
            </div>    
            <ul class="jv-navlinks">
                <li><a href="../../training.html" class="jv-navlink">Training</a></li>
                <li><a href="../../archives.html" class="jv-navlink">Archives</a></li>
                <li><a href="../../blogs.html" class="jv-navlink">Blogs</a></li>
            </ul>
    </nav>
</header>

<section class="jv-general-container">
    <div class="jv-breadcrumb-container">
        <span class="jv-breadcrumb-active"><a href="../../blogs.html">Blogs</a></span> 
        <span class="jv-breadcrumb-active"><a href="../../blogs.html">>> 2024</a></span> 
        <span class="jv-breadcrumb"> >> Chat with India's Budget 2024 using your Local CPU chatbot</span> 
    </div>
</section>

<section class="jv-general-container jv-general-top-gap-large">
    <div class="jv-section-title sz-h1">
        Chat with India's Budget 2024 using your Local CPU chatbot
    </div>
    <div class="jv-brand-emphasis">
        <div class="jv-bar-upper"></div>
        <div class="jv-bar-lower"></div>
    </div>
</section>

<section class="jv-general-container jv-section-container">
    <div class="jv-section-title sz-h3">
        1. Introduction
    </div>
    
    <div class="jv-section-body jv-section-text">
        Chatbot is a programme designed to simulate humanlike coversations. 
        It is capable of answering questions, getting external information, even solving complex coding problems. 
        In this tutorial we will build a Custom Chatbot to chat with our own document. 
        The document we will use is India's Budget 2024 Speech presented by Honâ€™ble Finance Minister Smt. Nirmala Sitharaman on July 23, 2024[1]. 
        The Budget Speech is very long and descriptive. Thus it is difficult for a common person to study the entirety. 
        But if we use a Custom Chatbot, we will be able to absorb most of it.
    </div>

    <div class="jv-section-title sz-h3">
        2. Overview: A Langchain-free approach
    </div>

    <div class="jv-section-body jv-section-text">
        <p>Developing a custom chatbot has become easier after the introduction of various open-source frameworks like Langchain. 
            These frameworks are great for prototype development, but they lack customization and suffers from niche documentation[2]. 
            So what's the alternative? Can we make a custom chatbot using only raw python and less lines of code? 
            Absolutely! This tutorial consists of <span class="jv-inline-emphasis">zero framework</span> and minimal dependencies.
        </p>

        <p>
            But wait, there's more. We also need an inference model. Using the best model of the world needs an API key which is behind a paywall[3]. 
            And if you wish to use an open-source model like Llama[4] or application like Ollama[5] you need a GPU. 
            On the other hand, hosting such applications on workhorse servers like AWS has become pretty scary due to their surprise bills[6]. 
            Do we have any way forward from this muddle?
        </p>

        <p>
            Voila! Here's the good news for you. This tutorial relieves you from all of this extreme capitalism. 
            We have used <span class="jv-inline-emphasis">Llamafile</span> to demonstrate how you can use your 7 years old i5-4670s to chat with your data[7]. 
            Haven't you heard about LLamafile? Well, Mozilla launched an open source project called <span class="jv-inline-emphasis">Llamafile</span> which collapse all the complexity of a full-stack Large Language Model (LLM) chatbot down to a single file that would run anywhere[8,9,10]. 
            It democratizes the use of LLMs in your local environment without GPU. Let's see how we can utilize their remarkable initiative.
        </p>

        <p>The overall structure of this tutorial is as follows:</p>

        <figure class="jv-full-width-figure">
            <img src="assets/chatbot_overview_fig.png" alt="Chatbot Overview" class="jv-fig">
        </figure>
    </div>

    <div class="jv-section-title sz-h3">
        3. Prerequisites
    </div>

<div class="jv-section-body jv-section-text">
<div class="jv-incell-code">
<pre><code class="language-shell"># Download a Llamafile
$ wget +o tiny.llamafile https://huggingface.co/Mozilla/TinyLlama-1.1B-Chat-v1.0-llamafile/resolve/main/TinyLlama-1.1B-Chat-v1.0.F16.llamafile
# Install the required packages
$ pip install -q docx2txt faiss-cpu requests scikit-learn
# Make sure the document is available
$ ls /docs | grep budget
<samp>$ budget_2024.docx</samp>
</code>
</pre>
</div>
</div>
</section>

<section class="jv-general-container jv-section-container">
    <div class="jv-section-title sz-h3">
        4. Building the Custom Chatbot
    </div>

    <div class="jv-section-title medium-headline">
        4.1. &nbsp; Load the Document
    </div>

    <div class="jv-section-body jv-section-text">
        <p>At first create a <span class="jv-inline-emphasis">document loader</span> to load documents from a folder. 
            The following loader is not necessary for this tutorial but it is a comprehensive approach on how one can load multiple documents at once.</p>

<div class="jv-incell-code">
<pre><code class="language-python">import os
from docx2txt import docx2txt

class SimpleDirectoryLoader(object):
    def __init__(self, directory, allowed_extensions=None):
        self.directory = directory
        self.allowed_extensions = allowed_extensions
        self.handlers = {
            '.docx': self.handle_docx,
        }
        self.data = []
    
    def load_files(self):
        for filename in os.listdir(self.directory):
            ext = os.path.splitext(filename)[-1]
            if (self.allowed_extensions is None or ext in self.allowed_extensions) and ext in self.handlers:
                self.handlers[ext](filename)
            elif self.allowed_extensions is not None and ext not in self.allowed_extensions:
                # print(f"Skipping {filename} with extension {ext}")
                pass
            else:
                print(f"No handler for {ext} files")
        return self.data

    def handle_docx(self, filename):
        text = docx2txt.process(os.path.join(self.directory, filename))
        self.data.append({'filename': filename, 'extension': '.docx', 'data': text})

</code>
</pre>
</div>

<div class="jv-incell-code">
<pre><code class="language-python"># Usage
allowed_extensions = ['.docx']
budget_loader = SimpleDirectoryLoader('path/to/your/docs/directory', allowed_extensions=allowed_extensions)
budget_doc = budget_loader.load_files()

# Print first 100 chars of the document
print(budget_doc[0]['data'][:100])
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.2. &nbsp; Chunk the Docs
    </div>

    <div class="jv-section-body jv-section-text">
        <p>A document can contain hundreds of pages each having thousands of words. 
            If we feed the bot with all of our document at once then it will fail to provide any response because most of the Large Language Models (LLM) have their maximum input context length. 
            Hence we need to create a list of smaller chunks from the document. 
            We create a chunk class to implement chunks by fixing total number of words in a chunk along with overlap.
        </p>

        <p><span class="jv-inline-emphasis">Note:</span> Overlapping is not neccessary but sufficient to provide relevant chunks when the context splits between more than one chunk.</p>
        
<div class="jv-incell-code">
<pre><code class="language-python">import re
from typing import List, Dict

class ChunkManager(object):
    def __init__(self, docs: List[Dict[str, str]]):
        self.combined_text = self._combine_texts(docs)
    
    def _combine_texts(self, docs: List[Dict[str, str]]) -> str:
        combined_text = ' '.join(doc['data'] for doc in docs)
        return re.sub(r'\n+', ' ', combined_text)

    def chunk_by_words_with_overlap(self, chunk_size: int, overlap: int) -> List[str]:
        words = self.combined_text.split()
        chunks = []
        step = chunk_size - overlap

        if overlap < 0:
            raise ValueError("Overlap must be a non-negative integer.")
        
        if step <= 0:
            raise ValueError("Overlap must be smaller than chunk size.")

        for i in range(0, len(words), step):
            chunk = ' '.join(words[i:i + chunk_size])
            chunks.append(chunk)
            
        return chunks

</code>
</pre>
</div>

<div class="jv-incell-code">
    <pre><code class="language-python"># Usage
chunk_size = 250
overlap = 100

chunks = ChunkManager(docs=budget_doc).chunk_by_words_with_overlap(chunk_size, overlap)
print(chunks)
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.3. &nbsp; Create Embeddings and save in a Vector Store
    </div>

    <div class="jv-section-body jv-section-text">
        <p>Embedding is the numerical representation of the data which makes it easier for algorithms to understand and analyze the relationships between different pieces of information. 
            It converts the data into fixed-size of vectors. After that we can use various search algorithm like <span class="jv-inline-emphasis">cosine similarity</span> to find the relevant data.
        </p>

        <p>In this tutorial, we use <span class="jv-inline-emphasis">TF-IDF</span> embeddings from scikit-learn library and 
            <span class="jv-inline-emphasis">FAISS</span> a cpu intesive vector storage from Facebook Research for storing the vectors.
        </p>

        <p><span class="jv-inline-emphasis">Note:</span> You can use any open source embedding models (from Hugging Face) or API (Gemini, OpenAI etc.) which are <span class="jv-inline-emphasis">dense</span> embedding models. We used <span class="jv-inline-emphasis">sparse</span> embedding from TF-IDF.</p>

<div class="jv-incell-code">
<pre><code class="language-python">import os
import faiss
import pickle
from sklearn.feature_extraction.text import TfidfVectorizer

class FAISS(object):
    def __init__(self, max_features=768):
        self.vectorizer = TfidfVectorizer(max_features=max_features)
        self.index = None
        self.texts = []

    # Create Embeddings
    def fit(self, texts):
        self.texts = texts
        embeddings = self.vectorizer.fit_transform(texts).toarray().astype('float32')
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(embeddings)
        return embeddings

    # Function for Similarity Search through Context and Query
    # Futher we fetch top k similar documents based on the query
    def search(self, query, k=10):
        query_embedding = self.vectorizer.transform([query]).toarray().astype('float32')
        distances, indices = self.index.search(query_embedding, k)
        similar_texts = [self.texts[idx] for idx in indices[0]]
        return similar_texts

    def save(self, dir_path, index_name='faiss'):
        os.makedirs(dir_path, exist_ok=True)

        with open(os.path.join(dir_path, f'{index_name}.pkl'), 'wb') as f:
            pickle.dump({'vectorizer': self.vectorizer, 'texts': self.texts}, f)
        
        faiss.write_index(self.index, os.path.join(dir_path, f'{index_name}.index'))

    def load(self, dir_path, index_name='faiss'):
        with open(os.path.join(dir_path, f'{index_name}.pkl'), 'rb') as f:
            data = pickle.load(f)
            self.vectorizer = data['vectorizer']
            self.texts = data['texts']
        
        self.index = faiss.read_index(os.path.join(dir_path, f'{index_name}.index'))

</code>
</pre>
</div>

<div class="jv-incell-code">
    <pre><code class="language-python"># Usage
faiss_index = FAISS()
faiss_index.fit(chunks)

# Save the embeddings for future use
faiss_index.save('path/to/your/embeddings/directory', index_name='budget_embeddings')

# Load the Budget Index
budget_index = FAISS()
budget_index.load('path/to/your/embeddings/directory', index_name='budget_embeddings')
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.4. &nbsp; Similarity Search
    </div>

    <div class="jv-section-body jv-section-text">
        <p>We searches through the embeddings using faiss's in-built <span class="jv-inline-emphasis">similarity search</span> function.</p>

<div class="jv-incell-code">
<pre><code class="language-python"># Query the Budget Index for similar documents
query = "Who represented the Budget 2024?"

no_of_docs_to_fetch = 10    # Get top 10 similar documents
context_chunks = budget_index.search(query, k=no_of_docs_to_fetch)
print(context_chunks)
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.5. &nbsp; Prompt Engineering
    </div>

    <div class="jv-section-body jv-section-text">
        <p>Before we proceed to do chat, we need to specify the model with an <span class="jv-inline-emphasis">instruction</span> about how the bot will behave. 
            This is very important part because we have seen that the quality of the response heavily depends on this prompt.
        </p>

        <p>Our prompt will have 3 parts:- Instruction, Context and the Query.</p>

<div class="jv-incell-code">
<pre><code class="language-python">prompt = """You are an expert in the analysis of Government Budgets.
The following comtexts will be from India's Budget 2024.
The user will ask questions about the Budget 2024 and you have to provide the answers based on the context.
Answer in a professional tone and use bullets and paragraphs to make the answer more readable.
If you can't find the answer in the context, reply with "I am sorry, I couldn't find the answer to your question.".
Don't put any external information in the answer.

Context: {context}

Question: {question}

Answer: Your answer goes here.
"""
</code>
</pre>
</div>

<div class="jv-incell-code">
    <pre><code class="language-python"># Construct the prompt
prompt = prompt.format(context=context_chunks, question=query)
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.6. &nbsp; Run Llamafile on CPU
    </div>

    <div class="jv-section-body jv-section-text">
        <p>We have to start the Llamafile as a <span class="jv-inline-emphasis">server</span> through terminal.</p>
<div class="jv-incell-code">
<pre><code class="language-shell"># Make the downloaded Llamafile executable
$ chmod +x tiny.llamafile
# Launch Llamafile as a server
$ ./tiny.llamafile  --nobrowser --server --port 8080 -c 4096
# This will load the model and start the server in the terminal 
<samp>$ llama server listening at http://127.0.0.1:8080</samp>
</code>
</pre>
</div>
    </div>

    <div class="jv-section-title medium-headline">
        4.7. &nbsp; Chat with the Budget Bot
    </div>

    <div class="jv-section-body jv-section-text">
        <p>Now we can chat with our Custom Budget Bot using the prompt we have created.</p>

<div class="jv-incell-code">
<pre><code class="language-python">import requests

class ChatLlamaFile(object):
    def __init__(self, host="localhost", port=8080):
        self.host = host
        self.port = port
        self.base_url = f"http://{host}:{port}"
        self.chat_url = f"{self.base_url}/v1/chat/completions"
        self.headers = {
            'Content-Type': 'application/json',
            'Authorization': 'Bearer no-key'
        }
    
    def chat(self, prompt, query):
        data = {
            "messages": [
                {
                    "role": "system",
                    "content": prompt
                },
                {
                    "role": "user",
                    "content": query
                }
            ]
        }
        response = requests.post(self.chat_url, headers=self.headers, json=data)
        return response.json()
</code>
</pre>
</div>

<div class="jv-incell-code">
<pre><code class="language-python"># Let's Chat
response = ChatLlamaFile().chat(prompt, query)
answer = response.get('choices')[0].get('message').get('content')

print("Query:", query)
print("Answer:", answer)
</code>
</pre>
</div>

<p>Example response:</p>

<div class="jv-incell-code">
<pre><code class="language-shell">Query: Who represented the Budget 2024?  
Answer: The Budget 2024 was presented by Finance Minister Nirmala Sitharaman.</s>
</code>
</pre>
</div>
    </div>

</section>



<footer class="jv-footer-container-align">
    <div class="jv-footer-container">
        <ul class="jv-footer-container-left">
            <li>
                <a href="https://github.com/aimplabs"><i class="fa-brands fa-github" style="color: gray;"></i> <span class="jv-ftnotes-icontxt">Codes/Data</span></a>
            </li>
            <li>
                <a href="https://twitter.com/aimplabs"><i class="fa-brands fa-twitter" style="color: #1DA1F2 ;"></i> <span class="jv-ftnotes-icontxt">Get updates/news</span></a>
            </li>
            <li>
                <a href="https://youtube.com/@aimplabs"> <i class="fa-brands fa-youtube" style="color: red;"></i> <span class="jv-ftnotes-icontxt">Video tutorials</span></a>
            </li>
            <li>
                <a href="https://www.facebook.com/aimplabs"> <i class="fa-brands fa-facebook" style="color: #1877F2;"></i> <span class="jv-ftnotes-icontxt">Trends & News</span></a>
            </li>             
        </ul>
        <div class="jv-footer-container-middle">
            <div class="jv-footer-brand-statements">
                <div class="jv-footer-brand-name" style="letter-spacing: 4px; font-family:'Spectral', serif; font-size: 18px; line-height: 30px;">AIMP LABS</div>
                <div class="jv-footer-brand-desc">A Private AI Research & Training Center</div>
                <div class="jv-footer-brand-desc">Computer Vision | Machine Learning | Cloud & Edge Computing </div>
                <div class="jv-footer-brand-desc">Copyright 2019 - 2022</div>
            </div>
        </div>
        <div class="jv-footer-container-right">
            <div class="jv-footer-brand-statements">
                <div class="jv-footer-brand-name">Contact us at contact@aimplabs.org</div>
                <div class="jv-footer-brand-desc"><a href="../../rudev.html">Are you a student developer/researcher?</a></div>
                <div class="jv-footer-brand-desc"><a href="../../about.html">About us</a></div>
            </div>
        </div>
    </div>
</footer>

<script>

function setsidenav() {
    let menu = document.querySelector(".menu-icon");

    if (menu.childNodes[1].textContent == 'menu') {
        menu.childNodes[1].textContent = 'close';
        document.querySelector('.jv-navlinks').style.display = 'flex';
    } else if (menu.childNodes[1].textContent == 'close') {
        menu.childNodes[1].textContent = 'menu';
        document.querySelector('.jv-navlinks').style.display = 'none';
    }

}
  var x = window.matchMedia("(max-width: 500px)")
  removeNavRt(x) // Call listener function at run time


</script>

</body>
</html>