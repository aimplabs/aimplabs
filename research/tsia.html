<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AIMP LABS | AI Research Center!</title>
    <link rel="stylesheet" href="../style.css">
    <link href="https://fonts.googleapis.com/css?family=Lora:400,700" rel="stylesheet">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.7/css/all.css">
  </head>
  <body>
    <header>
        <nav class="navbar">
            <div id="branding">
                    <a class="branding-logo" href="../index.html">
                    <img src="../assets/AnimatedA_transparent.png">
                    <h1><span class="highlight">AIMP</span>LABS</h1>
                    </a>
            </div>
            <div aria-labelledby="navigation-menu">
                <ul class="navbar__navigation">
                    <li><a href="../research.html">Research</a></li>
                    <li><a href="../reports.html">Reports</a></li>
                    <li><a href="../events.html">Events</a></li>
                    <li><a href="../about.html">About</a></li>
                </ul>
            </div>
            <div class="navbar__social-media">
                <ul class="navbar__links">
                    <a aria-label="facebook" href="https://www.facebook.com/aimplabs" target="facebook"><i class="fab fa-facebook "></i></a>
                    <a aria-label="github" href="https://github.com/aimplabs" target="github"><i class="fab fa-github"></i></a>
                    <a aria-label="twitter" href="#"><i class="fab fa-twitter"></i></a>
                </ul>
            </div>
        </nav>
    </header>
    <div class="breadcrumbs">  
        <a href="../index.html">Home</a> >> <a href="../research.html">Research</a>  >> TSIA
    </div>

<section class="article-header">
    <div class="article-title">
    Tumor Spheroid Image Analytics (TSIA): Automated Screening for Profiling Cancer Drug Resistance
    </div>
    <div class="article_border_layout"></div>
    <div class="article_bar_layout"></div>

    <div class="article-authors">
    Mohammad Azharuddin<sup>1</sup>, Sujoy Kumar Biswas<sup>2</sup>, Hirak Patra<sup>3</sup>, Karin Roberg<sup>1</sup>
    </div>   
    <div class="authors-affiliations">
        <ol class="affiliations">
            <li class="affiliation">Department of Biomedical and Clinical Sciences (BKV), Linköping University, Sweden</li>
            <li class="affiliation">AIMP Labs, Kolkata, India</li>
            <li class="affiliation">University College London, United Kingdom</li>
        </ol>
    </div>
</section>

<section class="article-abstract">
    <span class="article-abstract-logo">Abstract</span>
    <p class="article-abstract">
    A significant proportion of the cancer related deaths is attributed to drug resistance (>90%). This is a serious concern for cancer 
    patients as resistance to the given therapy leads to reduced drug response and disease recurrence. A healthcare solution that is 
    automated, cost-effective, and reliable, is the pressing need of this hour. However, realizing this goal requires studying and 
    benchmarking computer vision tools and techniques for establishing a robust image biomarker for drug profiling. At present, the 
    current state-of-the-art in visual recognition, i.e., the deep convolutional neural network, offers black-box solutions to 
    image recognition problems. In contrast, the field of biomedical science often requires interpretability as a strong criterion for 
    any expert system to aid in the diagnosis and therapy planning. Though the traditional machine learning techniques allow one to 
    build engineered and easy-to-interpret features, those methods are found to provide inferior results when compared with the performance 
    of deep learning. 
    In this joint venture on AI and health, our objective is to obtain the best of both the worlds, leveraging the excellent 
    pattern recognition power of deep convolutional neural networks while driving the decision-making process from an intuitive, 
    black-box free perspective. Perhaps the best value that comes with the old school of machine learning is the opportunity to 
    explore a dataset: manifold learning, cluster identifications, feature selections - these constitute an excellent set of tools 
    that empowers a biomedical expert to develop core understanding of the datasets. To facilitate this process, we realize that building a 
    large database associated with various annotations is key to our success. We are building a large databse of tumour spheroids, and characterizing them, 
    based on different drug responsiveness to chemotherapeutic agents. The spheroids will be monitored in a real time imaging system. 
    The effective in-vitro classifications are expected to provide the effectiveness of an existing or a new chemotherapeutic drug and 
    the extent that the tumour can offer resistance to that particular drug. By capturing dominant patterns and hidden behaviour 
    in image sets of tumour spheroids, the proposed computer vision solutions can provide a complete end-to-end apparatus for devising 
    personalised therapeutic strategy while recommending the suitable alternatives if the first line of therapy fails.</p>
</section>

<section class="article-abstract">
    <span class="article-abstract-logo">Methods and Materials</span>
    <p class="article-abstract">
        We pose the high throughput, automated monitoring of spheroid images as a 
        supervised. machine learning task with three classes of spheroid images, 
        namely, Sensitive, Moderately Sensitive, and Resistant (<b>Figure 1</b>). The objective of 
        the multiclass-AI system is to classify a novel test image into its most 
        appropriate class [1].   
    </p>
    <div class="full-img">
        <img src="../assets/car_03a.png" alt="Tumor Spheroids">
        <p class="img-caption"><b>Figure 1.</b> (a) We investigate the drug 
            resistance in head and neck tumor spheroids. To hypothesize whether 
            and how spheroid features vary when they become drug resistant with 
            a non-intervention approach, we have built a robust neural classifier 
            to classify these spheroids, into (b) ‘sensitive’, (c) ‘moderately sensitive’ and 
            (d) ‘resistant’ categories. A U-Net [2] style segmntation network yields foreground masks 
            giving us the (e) area and (f) perimeter distributions that clearly show marked 
            separability of the three classes in these two feature space. (g) The scatter diagram
            between area and perimeter further corroborates this fact. </p>
    </div>
    <p class="article-abstract">
        <b>Datasets and Python API </b> 
        Pre-treated Post-diagnosed (PTPD) HNSCC cancer cell lines are used to develop 
        the spheroids. We have a plan to establish at least 10 new HNSCC spheroids. 
        In brief, the HNSCC cell lines (monolayer or 2D) will be maintained in complete 
        keratinocyte serum-free growth medium. For the spheroid initiation, 
        200 µL of single-cell suspensions will be seeded in ultra-low attachment 
        (ULA) plates at varying cell densities. The plates will be incubated at a 
        humidified 5% CO2 atmosphere at 37ºC (48-72 hrs) for maturation. <br><br>
        
        Progression of spheroid formation is imaged on a daily basis (24, 48, and 72 h) 
        using an optical microscope with 5× or 10× objectives. The formation of tumour 
        spheroids will also be monitored every 3 hours by live-cell imaging using 
        Incucyte Zoom™ throughout the entire spheroid formation process with a 
        phase-contrast/fluorescence set up using the 10× objective. The images are 
        annotated according to drug sensitivity tests and then passed on to the 
        computer vision modules for Image analysis. <br><br>

        The image dataset is curated, annotated, and equipped with Python API. We have 
        undertaken a benchmarked study with the existing computer vision tools and techniques. 
        The results are very promising. Soon we shall release the entire tumor spheroid dataset, 
        annotation, and the codebase for scholarly pursuits. 
    </p>
</section>

<section class="article-abstract">
    <span class="article-abstract-logo">References</span>
    <ol class="references">
        <li>Azharuddin, M. et al., Dissecting multi drug resistance in head and neck cancer cells using multicellular tumor spheroids, 
            Nature Scientific Reports 9, 20066, 2019.</li>
        <li>Ronneberger, Olaf, et al., U-Net: Convolutional Networks for Biomedical Image Segmentation, International Conference on 
            Medical Image Computing and Computer-Assisted Intervention, pp. 234–241, 2015.
        </li>
    </ol>
</section>

<footer>
    <p>AIMP LABS</p> 
    <p>Calcutta, India </p>
    <p>Copyright &copy; 2020</p>
</footer>

</script>
</body>
</html>

